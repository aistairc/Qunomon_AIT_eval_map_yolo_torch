{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# AIT Development notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## notebook of structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "| #  | Name                                               | cells | for_dev | edit               | description                                                                |\n",
    "|----|----------------------------------------------------|-------|---------|--------------------|----------------------------------------------------------------------------|\n",
    "| 1  | [Environment detection](##1-Environment-detection) | 1     | No      | uneditable         | detect whether the notebook are invoked for packaging or in production     |\n",
    "| 2  | [Preparing AIT SDK](##2-Preparing-AIT-SDK)         | 1     | Yes     | uneditable         | download and install AIT SDK                                               |\n",
    "| 3  | [Dependency Management](##3-Dependency-Management) | 3     | Yes     | required(cell #2)  | generate requirements.txt for Docker container                             |\n",
    "| 4  | [Importing Libraries](##4-Importing-Libraries)     | 2     | Yes     | required(cell #1)  | import required libraries                                                  |\n",
    "| 5  | [Manifest Generation](##5-Manifest-Generation)     | 1     | Yes     | required           | generate AIT Manifest                                                      |\n",
    "| 6  | [Prepare for the Input](##6-Prepare-for-the-Input) | 1     | Yes     | required           | generate AIT Input JSON (inventory mapper)                                 |\n",
    "| 7  | [Initialization](##7-Initialization)               | 1     | No      | uneditable         | initialization for AIT execution                                           |\n",
    "| 8  | [Function definitions](##8-Function-definitions)   | N     | No      | required           | define functions invoked from Main area.<br> also define output functions. |\n",
    "| 9  | [Main Algorithms](##9-Main-Algorithms)             | 1     | No      | required           | area for main algorithms of an AIT                                         |\n",
    "| 10 | [Entry point](##10-Entry-point)                    | 1     | No      | uneditable         | an entry point where Qunomon invoke this AIT from here                     |\n",
    "| 11 | [License](##11-License)                            | 1     | Yes     | required           | generate license information                                               |\n",
    "| 12 | [Deployment](##12-Deployment)                      | 1     | Yes     | uneditable         | convert this notebook to the python file for packaging purpose             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## notebook template revision history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "1.0.1 2020/10/21\n",
    "\n",
    "* add revision history\n",
    "* separate `create requirements and pip install` editable and noeditable\n",
    "* separate `import` editable and noeditable\n",
    "\n",
    "1.0.0 2020/10/12\n",
    "\n",
    "* new cerarion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #1 Environment detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Determine whether to start AIT or jupyter by startup argument\n",
    "import sys\n",
    "is_ait_launch = (len(sys.argv) == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #2 Preparing AIT SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "if not is_ait_launch:\n",
    "    # get ait-sdk file name\n",
    "    from pathlib import Path\n",
    "    from glob import glob\n",
    "    import re\n",
    "    import os\n",
    "\n",
    "    current_dir = %pwd\n",
    "\n",
    "    ait_sdk_path = \"./ait_sdk-*-py3-none-any.whl\"\n",
    "    ait_sdk_list = glob(ait_sdk_path)\n",
    "    ait_sdk_name = os.path.basename(ait_sdk_list[-1])\n",
    "\n",
    "    # install ait-sdk\n",
    "    !pip install -q --upgrade pip\n",
    "    !pip install -q --no-deps --force-reinstall ./$ait_sdk_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #3 Dependency Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #3-1 [uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_requirements_generator import AITRequirementsGenerator\n",
    "    requirements_generator = AITRequirementsGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #3-2 [required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package('protobuf','3.19.4')\n",
    "    requirements_generator.add_package('torch','2.1.1')\n",
    "    requirements_generator.add_package('yolox','0.3.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #3-3 [uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package(f'./{ait_sdk_name}')\n",
    "    requirements_path = requirements_generator.create_requirements(current_dir)\n",
    "\n",
    "    !pip install -q -r $requirements_path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #4 Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #4-1 [required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import contextlib\n",
    "import io\n",
    "import json\n",
    "import tempfile\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from yolox.exp import get_exp\n",
    "from yolox.data import COCODataset, ValTransform\n",
    "from yolox.utils import (\n",
    "    postprocess,\n",
    "    xyxy2xywh\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #4-2 [uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# must use modules\n",
    "from os import path\n",
    "import shutil  # do not remove\n",
    "from ait_sdk.common.files.ait_input import AITInput  # do not remove\n",
    "from ait_sdk.common.files.ait_output import AITOutput  # do not remove\n",
    "from ait_sdk.common.files.ait_manifest import AITManifest  # do not remove\n",
    "from ait_sdk.develop.ait_path_helper import AITPathHelper  # do not remove\n",
    "from ait_sdk.utils.logging import get_logger, log, get_log_path  # do not remove\n",
    "from ait_sdk.develop.annotation import measures, resources, downloads, ait_main  # do not remove\n",
    "# must use modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #5 Manifest Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_manifest_generator import AITManifestGenerator\n",
    "    manifest_generator = AITManifestGenerator(current_dir)\n",
    "    manifest_generator.set_ait_name('eval_map_yolox_torch')\n",
    "    manifest_generator.set_ait_description('Evaluate performance of YoloX (Original Pytorch Implementation) model using pycocotools.')\n",
    "    manifest_generator.set_ait_source_repository('https://github.com/aistairc/eval-map-yolox-torch')\n",
    "    manifest_generator.set_ait_version('0.1')\n",
    "    manifest_generator.add_ait_keywords('AIT')\n",
    "    manifest_generator.add_ait_keywords('Object Detection')\n",
    "    manifest_generator.add_ait_keywords('YoloX')\n",
    "    manifest_generator.add_ait_keywords('mAP')\n",
    "    manifest_generator.set_ait_quality('https://ait-hub.pj.aist.go.jp/ait-hub/api/0.0.1/qualityDimensions/機械学習品質マネジメントガイドライン第三版/C-1機械学習モデルの正確性')\n",
    "    \n",
    "    # AIT Inventories\n",
    "    ## Model Weights\n",
    "    model_weights_req = manifest_generator.format_ait_inventory_requirement(format_=['pt'])\n",
    "    manifest_generator.add_ait_inventories(name='torch_weights',\n",
    "                                             type_='model',\n",
    "                                             description=\"Specify state_dict saved through torch.save API. \"\n",
    "                                                         \"Assumed architecture of this weights file must match with 'torch_model_module''s one.\",\n",
    "                                             requirement=model_weights_req)\n",
    "    \n",
    "    ## Dataset\n",
    "    ds_req = manifest_generator.format_ait_inventory_requirement(format_=['zip'])\n",
    "    manifest_generator.add_ait_inventories(name='coco_dataset', \n",
    "                                             type_='dataset', \n",
    "                                             description='Specify test dataset. They must be conform to the COCO format.',\n",
    "                                             requirement=ds_req)\n",
    "    \n",
    "    # AIT Parameters\n",
    "    manifest_generator.add_ait_parameters(name='model_name',type_='str',description='Specify model name (Such as yolox-s, yolox-tiny, yolox-nano, ...).', default_val='yolox_s')\n",
    "    manifest_generator.add_ait_parameters(name='annotation_file_name',type_='str',description='Specify the name of the annotation file in the datasets.zip/annotations directory.', default_val='instaces_val2017.json')\n",
    "    manifest_generator.add_ait_parameters(name='image_path',type_='str',description='Specify the name of the image directory in the datasets.zip/annotations directory.', default_val='val2017')\n",
    "    \n",
    "    manifest_generator.add_ait_parameters(name='image_width',type_='int',description='Image size after preprocess (given to cocoeval)', default_val='640')\n",
    "    manifest_generator.add_ait_parameters(name='image_height',type_='int',description='Image size after preprocess (given to cocoeval)', default_val='640')\n",
    "    manifest_generator.add_ait_parameters(name='confthre',type_='float',description='Minimum confidence threshold', default_val='0.01')\n",
    "    manifest_generator.add_ait_parameters(name='nmsthre',type_='float',description='IoU threshold for NMS process', default_val='0.65')\n",
    "    manifest_generator.add_ait_parameters(name='num_classes',type_='int',description='Number of classes of detector', default_val='80')\n",
    "    manifest_generator.add_ait_parameters(name='batch_size',type_='int',description='Specify batch size for the evaluation.', default_val='64')\n",
    "    \n",
    "    # AIT Measuers\n",
    "    manifest_generator.add_ait_measures(name='map',type_='float',description='mAP@[.5 : .05 : 0.95]',structure='single',min='0')\n",
    "    manifest_generator.add_ait_measures(name='ap_50',type_='float',description='AP@.5',structure='single',min='0')\n",
    "    manifest_generator.add_ait_measures(name='ap_75',type_='float',description='AP@.75',structure='single',min='0')\n",
    "    manifest_generator.add_ait_measures(name='map_small',type_='float',description='mAP, with only small (from 0x0 to 32x32) bboxes.',structure='single',min='0')\n",
    "    manifest_generator.add_ait_measures(name='map_medium',type_='float',description='mAP, with only medium (from 32x32 to 96x96) bboxes.',structure='single',min='0')\n",
    "    manifest_generator.add_ait_measures(name='map_large',type_='float',description='mAP, with only large (from 96x96 to 10000x10000) bboxes.',structure='single',min='0')\n",
    "    manifest_generator.add_ait_measures(name='mrec_maxdet1',type_='float',description='mRecall[0 : 0.01 : 1] at max_det==1',structure='single',min='0')\n",
    "    manifest_generator.add_ait_measures(name='mrec_maxdet10',type_='float',description='mRecall[0 : 0.01 : 1] at max_det==10',structure='single',min='0')\n",
    "    manifest_generator.add_ait_measures(name='mrec_maxdet100',type_='float',description='mRecall[0 : 0.01 : 1] at max_det==100',structure='single',min='0')\n",
    "    manifest_generator.add_ait_measures(name='mrec_small',type_='float',description='mRecall, with only small (from 0x0 to 32x32) bboxes.',structure='single',min='0')\n",
    "    manifest_generator.add_ait_measures(name='mrec_medium',type_='float',description='mRecall, with only medium (from 32x32 to 96x96) bboxes.',structure='single',min='0')\n",
    "    manifest_generator.add_ait_measures(name='mrec_large',type_='float',description='mRecall, with only large (from 96x96 to 10000x10000) bboxes.',structure='single',min='0')\n",
    "\n",
    "    manifest_generator.add_ait_resources(name='summarized_text',type_='text',description='summarized results (cocoeval output)')\n",
    "\n",
    "    manifest_generator.add_ait_downloads(name='Log',description='AIT実行ログ')\n",
    "\n",
    "    manifest_path = manifest_generator.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #6 Prepare for the Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_input_generator import AITInputGenerator\n",
    "    input_generator = AITInputGenerator(manifest_path)\n",
    "    input_generator.add_ait_inventories(name='coco_dataset',\n",
    "                                        value='coco_dataset/dataset.zip')\n",
    "    input_generator.add_ait_inventories(name='torch_weights',\n",
    "                                        value='torch_weights/yolox_s.pth')\n",
    "    input_generator.set_ait_params(name='model_name',value='yolox_s')\n",
    "    input_generator.set_ait_params(name='annotation_file_name',value='instances_valreduced.json')\n",
    "    input_generator.set_ait_params(name='image_path',value='valreduced')\n",
    "    input_generator.set_ait_params(name='image_width',value='640')\n",
    "    input_generator.set_ait_params(name='image_height',value='640')\n",
    "    input_generator.set_ait_params(name='confthre',value='0.01')\n",
    "    input_generator.set_ait_params(name='nmsthre',value='0.65')\n",
    "    input_generator.set_ait_params(name='num_classes',value='80')\n",
    "    input_generator.set_ait_params(name='batch_size',value='16')\n",
    "    input_generator.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #7 Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "\n",
    "ait_manifest = AITManifest()\n",
    "ait_input = AITInput(ait_manifest)\n",
    "ait_output = AITOutput(ait_manifest)\n",
    "\n",
    "if is_ait_launch:\n",
    "    # launch from AIT\n",
    "    current_dir = path.dirname(path.abspath(__file__))\n",
    "    path_helper = AITPathHelper(argv=sys.argv, ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "else:\n",
    "    # launch from jupyter notebook\n",
    "    # ait.input.json make in input_dir\n",
    "    input_dir = '/usr/local/qai/mnt/ip/job_args/1/1'\n",
    "    current_dir = %pwd\n",
    "    path_helper = AITPathHelper(argv=['', input_dir], ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "\n",
    "ait_input.read_json(path_helper.get_input_file_path())\n",
    "ait_manifest.read_json(path_helper.get_manifest_file_path())\n",
    "\n",
    "### do not edit cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #8 Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is a modified version of the YoloX Code.\n",
    "# Original Copyright Notice is shown below.\n",
    "# Detailed license information is placed at repository root and will be included in the AIT package.\n",
    "\n",
    "# Copyright (c) Megvii, Inc. and its affiliates.\n",
    "\n",
    "class CPUCOCOEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataloader,\n",
    "        img_size: int,\n",
    "        confthre: float,\n",
    "        nmsthre: float,\n",
    "        num_classes: int\n",
    "    ):\n",
    "        self.dataloader = dataloader\n",
    "        self.img_size = img_size\n",
    "        self.confthre = confthre\n",
    "        self.nmsthre = nmsthre\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def evaluate(\n",
    "        self, model\n",
    "    ):\n",
    "        model = model.eval()\n",
    "        ids = []\n",
    "        data_list = []\n",
    "        output_data = defaultdict()\n",
    "        progress_bar = tqdm\n",
    "\n",
    "        for imgs, _, info_imgs, ids in progress_bar(self.dataloader):\n",
    "            with torch.no_grad():\n",
    "                outputs = model(imgs)\n",
    "\n",
    "                outputs = postprocess(\n",
    "                    outputs, self.num_classes, self.confthre, self.nmsthre\n",
    "                )\n",
    "\n",
    "            data_list_elem, image_wise_data = self.convert_to_coco_format(\n",
    "                outputs, info_imgs, ids, return_outputs=True)\n",
    "            data_list.extend(data_list_elem)\n",
    "            output_data.update(image_wise_data)\n",
    "\n",
    "        eval_results = self.evaluate_prediction(data_list)\n",
    "\n",
    "        return eval_results\n",
    "\n",
    "    def convert_to_coco_format(self, outputs, info_imgs, ids, return_outputs=False):\n",
    "        data_list = []\n",
    "        image_wise_data = defaultdict(dict)\n",
    "        for (output, img_h, img_w, img_id) in zip(\n",
    "            outputs, info_imgs[0], info_imgs[1], ids\n",
    "        ):\n",
    "            if output is None:\n",
    "                continue\n",
    "            output = output.cpu()\n",
    "\n",
    "            bboxes = output[:, 0:4]\n",
    "\n",
    "            # preprocessing: resize\n",
    "            scale = min(\n",
    "                self.img_size[0] / float(img_h), self.img_size[1] / float(img_w)\n",
    "            )\n",
    "            bboxes /= scale\n",
    "            cls = output[:, 6]\n",
    "            scores = output[:, 4] * output[:, 5]\n",
    "\n",
    "            image_wise_data.update({\n",
    "                int(img_id): {\n",
    "                    \"bboxes\": [box.numpy().tolist() for box in bboxes],\n",
    "                    \"scores\": [score.numpy().item() for score in scores],\n",
    "                    \"categories\": [\n",
    "                        self.dataloader.dataset.class_ids[int(cls[ind])]\n",
    "                        for ind in range(bboxes.shape[0])\n",
    "                    ],\n",
    "                }\n",
    "            })\n",
    "\n",
    "            bboxes = xyxy2xywh(bboxes)\n",
    "\n",
    "            for ind in range(bboxes.shape[0]):\n",
    "                label = self.dataloader.dataset.class_ids[int(cls[ind])]\n",
    "                pred_data = {\n",
    "                    \"image_id\": int(img_id),\n",
    "                    \"category_id\": label,\n",
    "                    \"bbox\": bboxes[ind].numpy().tolist(),\n",
    "                    \"score\": scores[ind].numpy().item(),\n",
    "                    \"segmentation\": [],\n",
    "                }  # COCO json format\n",
    "                data_list.append(pred_data)\n",
    "\n",
    "        if return_outputs:\n",
    "            return data_list, image_wise_data\n",
    "        return data_list\n",
    "\n",
    "    def evaluate_prediction(self, data_dict):\n",
    "        info = \"\"\n",
    "        \n",
    "        # Evaluate the Dt (detection) json comparing with the ground truth\n",
    "        if len(data_dict) > 0:\n",
    "            cocoGt = self.dataloader.dataset.coco\n",
    "            \n",
    "            _, tmp = tempfile.mkstemp()\n",
    "            json.dump(data_dict, open(tmp, \"w\"))\n",
    "            cocoDt = cocoGt.loadRes(tmp)\n",
    "\n",
    "            cocoEval = COCOeval(cocoGt, cocoDt, \"bbox\")            \n",
    "            cocoEval.evaluate()\n",
    "            cocoEval.accumulate()\n",
    "            redirect_string = io.StringIO()\n",
    "            with contextlib.redirect_stdout(redirect_string):\n",
    "                cocoEval.summarize()\n",
    "            info += redirect_string.getvalue()\n",
    "            \n",
    "            return cocoEval, info\n",
    "        else:\n",
    "            return None, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_metric(ceval, p, metric_type, iou=None, area_range=\"all\", max_det=100):\n",
    "    evalobj = ceval[metric_type]\n",
    "    a_indices = [i for i, arl in enumerate(p.areaRngLbl) if area_range == arl]\n",
    "    d_indices = [i for i, mdets in enumerate(p.maxDets) if max_det == mdets]\n",
    "\n",
    "    if metric_type == \"precision\":\n",
    "        if iou is None:\n",
    "            resobj = evalobj[:,:,:,a_indices, d_indices]\n",
    "            result = np.mean(resobj[resobj> -1])\n",
    "            return float(result)\n",
    "        else:\n",
    "            mask = np.where(iou == p.iouThrs)[0]\n",
    "            resobj = evalobj[mask][:,:,:,a_indices, d_indices]\n",
    "            result = np.mean(resobj[resobj> -1])\n",
    "            return float(result)\n",
    "    \n",
    "    elif metric_type == \"recall\":\n",
    "        if iou is None:\n",
    "            resobj = evalobj[:,:,a_indices, d_indices]\n",
    "            result = np.mean(resobj[resobj> -1])\n",
    "            return float(result)\n",
    "        else:\n",
    "            mask = np.where(iou == p.iouThrs)[0]\n",
    "            resobj = evalobj[mask][:,:,a_indices, d_indices]\n",
    "            result = np.mean(resobj[resobj> -1])\n",
    "            return float(result)\n",
    "        \n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'map')\n",
    "def calc_map(cocoeval, p):\n",
    "    return gather_metric(cocoeval, p, \"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'ap_50')\n",
    "def calc_ap_50(cocoeval, p):\n",
    "    return gather_metric(cocoeval, p, \"precision\", iou=.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'ap_75')\n",
    "def calc_ap_75(cocoeval, p):\n",
    "    return gather_metric(cocoeval, p, \"recall\", iou=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'map_small')\n",
    "def calc_map_small(cocoeval, p):\n",
    "    return gather_metric(cocoeval, p, \"recall\", area_range=\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'map_medium')\n",
    "def calc_map_medium(cocoeval, p):\n",
    "    return gather_metric(cocoeval, p, \"recall\", area_range=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'map_large')\n",
    "def calc_map_large(cocoeval, p):\n",
    "    return gather_metric(cocoeval, p, \"recall\", area_range=\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'mrec_maxdet1')\n",
    "def calc_mrec_maxdet1(cocoeval, p):\n",
    "    return gather_metric(cocoeval, p, \"recall\", max_det=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'mrec_maxdet10')\n",
    "def calc_mrec_maxdet10(cocoeval, p):\n",
    "    return gather_metric(cocoeval, p, \"recall\", max_det=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'mrec_maxdet100')\n",
    "def calc_mrec_maxdet100(cocoeval, p):\n",
    "    return gather_metric(cocoeval, p, \"recall\", max_det=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'mrec_small')\n",
    "def calc_mrec_small(cocoeval, p):\n",
    "    return gather_metric(cocoeval, p, \"recall\", area_range=\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'mrec_medium')\n",
    "def calc_mrec_medium(cocoeval, p):\n",
    "    return gather_metric(cocoeval, p, \"recall\", area_range=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'mrec_large')\n",
    "def calc_mrec_large(cocoeval, p):\n",
    "    return gather_metric(cocoeval, p, \"recall\", area_range=\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@resources(ait_output, path_helper, 'summarized_text', \"summary.txt\")\n",
    "def save_summarized_text(summary, file_path: str=None): \n",
    "    os.makedirs(str(Path(file_path).parent), exist_ok=True)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'Log', 'ait.log')\n",
    "def move_log(file_path: str=None):\n",
    "    shutil.move(get_log_path(), file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #9 Main Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@ait_main(ait_output, path_helper)\n",
    "def main() -> None:    \n",
    "    # Prepare fixed parameters\n",
    "    # TODO: Parameterize these values\n",
    "    img_w = ait_input.get_method_param_value('image_width')\n",
    "    img_h = ait_input.get_method_param_value('image_height')\n",
    "    img_size = (img_w, img_h)\n",
    "    \n",
    "    conf_thre = ait_input.get_method_param_value('confthre')\n",
    "    nms_thre = ait_input.get_method_param_value('nmsthre')\n",
    "    num_classes = ait_input.get_method_param_value('num_classes')\n",
    "    \n",
    "    # Prepare for the model\n",
    "    model_name = ait_input.get_method_param_value('model_name')\n",
    "    exp = get_exp(None, model_name)\n",
    "    model = exp.get_model()\n",
    "    \n",
    "    model_weights_path = ait_input.get_inventory_path('torch_weights')\n",
    "    model_weights = torch.load(model_weights_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(model_weights[\"model\"])\n",
    "    \n",
    "    # load dataset\n",
    "    ds_path = ait_input.get_inventory_path('coco_dataset')\n",
    "    annotation_file_name = ait_input.get_method_param_value('annotation_file_name')\n",
    "    image_path = ait_input.get_method_param_value('image_path')\n",
    "    batch_size = ait_input.get_method_param_value('batch_size')\n",
    "    \n",
    "    if os.path.exists(\"./temp\"):\n",
    "        shutil.rmtree(\"./temp\")\n",
    "    os.makedirs(\"./temp\", exist_ok=True)\n",
    "    pre_dirs = set(os.listdir(\"./temp\"))\n",
    "    shutil.unpack_archive(ds_path, extract_dir=\"./temp\")\n",
    "    post_dirs = set(os.listdir(\"./temp\"))\n",
    "    extracted = list(pre_dirs ^ post_dirs)[0]\n",
    "    \n",
    "    unpacked_dir_name = f\"./temp/{extracted}\"\n",
    "    \n",
    "    ds = COCODataset(\n",
    "        data_dir=f\"{unpacked_dir_name}\",\n",
    "        json_file=annotation_file_name,\n",
    "        name=image_path,\n",
    "        img_size=img_size,\n",
    "        preproc=ValTransform()\n",
    "    )\n",
    " \n",
    "    ds2 = ds\n",
    "    \n",
    "#     code for testing with partial dataset.\n",
    "#     ds2 = torch.utils.data.Subset(ds, range(32))\n",
    "    \n",
    "    sampler = torch.utils.data.SequentialSampler(ds2)\n",
    "    loader_kwargs = {\n",
    "        \"num_workers\": 0,\n",
    "        \"pin_memory\": True,\n",
    "        \"sampler\": sampler,\n",
    "        \"batch_size\": batch_size\n",
    "    }\n",
    "    ds_loader = torch.utils.data.DataLoader(ds, **loader_kwargs)\n",
    "\n",
    "    evaluator = CPUCOCOEvaluator(\n",
    "        dataloader=ds_loader,\n",
    "        img_size=img_size,\n",
    "        confthre=conf_thre,\n",
    "        nmsthre=nms_thre,\n",
    "        num_classes=num_classes)\n",
    "    \n",
    "    ceval, summarized_text = evaluator.evaluate(model)\n",
    "    \n",
    "    save_summarized_text(summarized_text)\n",
    "    \n",
    "    calc_map(ceval.eval, ceval.params)\n",
    "    calc_ap_50(ceval.eval, ceval.params)\n",
    "    calc_ap_75(ceval.eval, ceval.params)\n",
    "    calc_map_small(ceval.eval, ceval.params)\n",
    "    calc_map_medium(ceval.eval, ceval.params)\n",
    "    calc_map_large(ceval.eval, ceval.params)\n",
    "    calc_mrec_maxdet1(ceval.eval, ceval.params)\n",
    "    calc_mrec_maxdet10(ceval.eval, ceval.params)\n",
    "    calc_mrec_maxdet100(ceval.eval, ceval.params)\n",
    "    calc_mrec_small(ceval.eval, ceval.params)\n",
    "    calc_mrec_medium(ceval.eval, ceval.params)\n",
    "    calc_mrec_large(ceval.eval, ceval.params)\n",
    "    \n",
    "    move_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #10 Entry point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:11<00:00,  5.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.48s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.33s).\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #11 License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample ##\n",
    "ait_owner='AIST'\n",
    "ait_creation_year='2023'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #12 Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.deploy import prepare_deploy\n",
    "    from ait_sdk.license.license_generator import LicenseGenerator\n",
    "    \n",
    "    current_dir = %pwd\n",
    "    prepare_deploy(ait_sdk_name, current_dir, requirements_path)\n",
    "    \n",
    "    # output License.txt\n",
    "    license_generator = LicenseGenerator()\n",
    "    license_generator.write('../top_dir/LICENSE.txt', ait_creation_year, ait_owner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc00c6a56d87bd8bd7773e730c60ddfdb8804da6b7537df09499efbcf81630f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
